{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "desafio final poems",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i5u6NInb34j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "# import locale\n",
        "# locale.setlocale(locale.LC_ALL, 'pt_BR.UTF-8')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMoT1T6ScQ-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9ff710e-c36c-4468-b0d6-8c8516e6e5b4"
      },
      "source": [
        "# check if GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU!')\n",
        "else: \n",
        "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9E2V0aOb6nG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "1d1f0ddd-da95-4824-e15c-0f11fa823cde"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/portuguese-poems.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15543, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Author</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cecília Meireles</td>\n",
              "      <td>Retrato</td>\n",
              "      <td>Eu não tinha este rosto de hoje,\\r\\nAssim calm...</td>\n",
              "      <td>1018431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fernando Pessoa</td>\n",
              "      <td>Para ser grande, sê inteiro: nada</td>\n",
              "      <td>Para ser grande, sê inteiro: nada\\r\\nTeu exage...</td>\n",
              "      <td>1979413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Marina Colasanti</td>\n",
              "      <td>Eu sei, mas não devia</td>\n",
              "      <td>Eu sei que a gente se acostuma. Mas não devia....</td>\n",
              "      <td>301509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carlos Drummond de Andrade</td>\n",
              "      <td>Quadrilha</td>\n",
              "      <td>João amava Teresa que amava Raimundo\\r\\nque am...</td>\n",
              "      <td>1421206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eugénio de Andrade</td>\n",
              "      <td>É urgente o amor</td>\n",
              "      <td>É urgente o amor.\\r\\nÉ urgente um barco no mar...</td>\n",
              "      <td>621197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Author  ...    Views\n",
              "0            Cecília Meireles  ...  1018431\n",
              "1             Fernando Pessoa  ...  1979413\n",
              "2            Marina Colasanti  ...   301509\n",
              "3  Carlos Drummond de Andrade  ...  1421206\n",
              "4          Eugénio de Andrade  ...   621197\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtSf9qVRb60b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "276c3fe7-6dca-4cec-c440-50abbb80fcda"
      },
      "source": [
        "df.Author.value_counts(normalize=True)[:10].plot.bar()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4f0223ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc6mYhf0b63B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "74da0fd6-3aa3-46e0-83b4-27ce82eb7628"
      },
      "source": [
        "print('Contents vazios')\n",
        "print(df[df['Content'].isnull()].shape[0])\n",
        "print()\n",
        "df = df[df['Content'].notnull()]\n",
        "print('Content vazio')\n",
        "print(df[df['Content'].isnull()].shape[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contents vazios\n",
            "2\n",
            "\n",
            "Content vazio\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiZwmqWQKLoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df = df.sample(300)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SKxswdUb65v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "3534f161-8148-40b2-df38-820dd05a31de"
      },
      "source": [
        "df = df.copy()\n",
        "df['Content'] = df['Content'].str.replace('\\s',' ' )\n",
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Author</th>\n",
              "      <th>Title</th>\n",
              "      <th>Content</th>\n",
              "      <th>Views</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cecília Meireles</td>\n",
              "      <td>Retrato</td>\n",
              "      <td>Eu não tinha este rosto de hoje,  Assim calmo,...</td>\n",
              "      <td>1018431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fernando Pessoa</td>\n",
              "      <td>Para ser grande, sê inteiro: nada</td>\n",
              "      <td>Para ser grande, sê inteiro: nada  Teu exagera...</td>\n",
              "      <td>1979413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Marina Colasanti</td>\n",
              "      <td>Eu sei, mas não devia</td>\n",
              "      <td>Eu sei que a gente se acostuma. Mas não devia....</td>\n",
              "      <td>301509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Carlos Drummond de Andrade</td>\n",
              "      <td>Quadrilha</td>\n",
              "      <td>João amava Teresa que amava Raimundo  que amav...</td>\n",
              "      <td>1421206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eugénio de Andrade</td>\n",
              "      <td>É urgente o amor</td>\n",
              "      <td>É urgente o amor.  É urgente um barco no mar. ...</td>\n",
              "      <td>621197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Author  ...    Views\n",
              "0            Cecília Meireles  ...  1018431\n",
              "1             Fernando Pessoa  ...  1979413\n",
              "2            Marina Colasanti  ...   301509\n",
              "3  Carlos Drummond de Andrade  ...  1421206\n",
              "4          Eugénio de Andrade  ...   621197\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC2-qb2_8eVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfCoontent = df[['Content']]\n",
        "dfCoontent.to_csv('/content/drive/My Drive/Colab Notebooks/content.txt',header=None, index=None, sep=' ', mode='a')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_mx9_AXMfzd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "601y-pka-xut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# open text file and read in data as `text`\n",
        "with open('/content/drive/My Drive/Colab Notebooks/content.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asB8jLR0jW-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0fdbe98e-6066-4ff1-d9ff-34a27c7b9cbf"
      },
      "source": [
        "text =  text.replace('\"','')\n",
        "text = re.sub(' +',' ',text)\n",
        "text = re.sub('\\n',' ',text)\n",
        "text[0:200]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Uma certa quantidade de gente à procura de gente à procura duma certa quantidade Soma: uma paisagem extremamente à procura o problema da luz (adrede ligado ao problema da vergonha) e o problema do qua'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFVFNzVQ4MaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUU1riXFd8QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# encode the text and map each character to an integer and vice versa\n",
        "\n",
        "# we create two dictionaries:\n",
        "# 1. int2char, which maps integers to characters\n",
        "# 2. char2int, which maps characters to unique integers\n",
        "\n",
        "chars = tuple(set(text))\n",
        "int2char = dict(enumerate(chars))\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "\n",
        "# encode the text\n",
        "encoded = np.array([char2int[ch] for ch in text])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IItu1qp1b68s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def one_hot_encode(arr, n_labels):\n",
        "    \n",
        "    # Initialize the the encoded array\n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "    \n",
        "    # Fill the appropriate elements with ones\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    \n",
        "    # Finally reshape it to get back to the original array\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ycA4HBKb6_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f328abd0-43c0-45a1-df65-f1df9ece8eb5"
      },
      "source": [
        "# check that the function works as expected\n",
        "test_seq = np.array([[0, 5, 1]])\n",
        "one_hot = one_hot_encode(test_seq, 8)\n",
        "\n",
        "print(one_hot)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L58UnDAwb7Cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    '''Create a generator that returns batches of size\n",
        "       batch_size x seq_length from arr.\n",
        "       \n",
        "       Arguments\n",
        "       ---------\n",
        "       arr: Array you want to make batches from\n",
        "       batch_size: Batch size, the number of sequences per batch\n",
        "       seq_length: Number of encoded chars in a sequence\n",
        "    '''\n",
        "    \n",
        "    batch_size_total = batch_size * seq_length\n",
        "    # total number of batches we can make\n",
        "    n_batches = len(arr)//batch_size_total\n",
        "    \n",
        "    # Keep only enough characters to make full batches\n",
        "    arr = arr[:n_batches * batch_size_total]\n",
        "    # Reshape into batch_size rows\n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    \n",
        "    # iterate through the array, one sequence at a time\n",
        "    for n in range(0, arr.shape[1], seq_length):\n",
        "        # The features\n",
        "        x = arr[:, n:n+seq_length]\n",
        "        # The targets, shifted by one\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
        "        except IndexError:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLunwo5ub7Fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNN(nn.Module):\n",
        "        \n",
        "        def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
        "                                   drop_prob=0.5, lr=0.001):\n",
        "            super().__init__()\n",
        "            self.drop_prob = drop_prob\n",
        "            self.n_layers = n_layers\n",
        "            self.n_hidden = n_hidden\n",
        "            self.lr = lr\n",
        "            \n",
        "            # creating character dictionaries\n",
        "            self.chars = tokens\n",
        "            self.int2char = dict(enumerate(self.chars))\n",
        "            self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
        "            \n",
        "            #lstm layer\n",
        "            self.lstm=nn.LSTM(len(self.chars),n_hidden,n_layers,\n",
        "                              dropout=drop_prob,batch_first=True)\n",
        "            \n",
        "            #dropout layer\n",
        "            self.dropout=nn.Dropout(drop_prob)\n",
        "            \n",
        "            #output layer\n",
        "            self.fc=nn.Linear(n_hidden,len(self.chars))\n",
        "    \n",
        "        \n",
        "        def forward(self, x, hidden):\n",
        "            ''' Forward pass through the network. \n",
        "                These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "            ## Get the outputs and the new hidden state from the lstm\n",
        "            r_output, hidden = self.lstm(x, hidden)\n",
        "            \n",
        "            ## pass through a dropout layer\n",
        "            out = self.dropout(r_output)\n",
        "            \n",
        "            # Stack up LSTM outputs using view\n",
        "            # you may need to use contiguous to reshape the output\n",
        "            out = out.contiguous().view(-1, self.n_hidden)\n",
        "            \n",
        "            ## put x through the fully-connected layer\n",
        "            out = self.fc(out)\n",
        "            return out, hidden\n",
        "        \n",
        "        \n",
        "        def init_hidden(self, batch_size):\n",
        "            ''' Initializes hidden state '''\n",
        "            # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "            # initialized to zero, for hidden state and cell state of LSTM\n",
        "            weight = next(self.parameters()).data\n",
        "            \n",
        "            if (train_on_gpu):\n",
        "                hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "            else:\n",
        "                hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                          weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "            \n",
        "            return hidden\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdby9pMeb7Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=1000):\n",
        "        ''' Training a network \n",
        "        \n",
        "            Arguments\n",
        "            ---------\n",
        "            \n",
        "            net: CharRNN network\n",
        "            data: text data to train the network\n",
        "            epochs: Number of epochs to train\n",
        "            batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
        "            seq_length: Number of character steps per mini-batch\n",
        "            lr: learning rate\n",
        "            clip: gradient clipping\n",
        "            val_frac: Fraction of data to hold out for validation\n",
        "            print_every: Number of steps for printing training and validation loss\n",
        "        \n",
        "        '''\n",
        "        net.train()\n",
        "        \n",
        "        opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "        # create training and validation data\n",
        "        val_idx = int(len(data)*(1-val_frac))\n",
        "        data, val_data = data[:val_idx], data[val_idx:]\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            net.cuda()\n",
        "        \n",
        "        counter = 0\n",
        "        n_chars = len(net.chars)\n",
        "        for e in range(epochs):\n",
        "            # initialize hidden state\n",
        "            h = net.init_hidden(batch_size)\n",
        "            \n",
        "            for x, y in get_batches(data, batch_size, seq_length):\n",
        "                counter += 1\n",
        "                \n",
        "                # One-hot encode our data and make them Torch tensors\n",
        "                x = one_hot_encode(x, n_chars)\n",
        "                inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                \n",
        "                if(train_on_gpu):\n",
        "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
        "    \n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                h = tuple([each.data for each in h])\n",
        "    \n",
        "                # zero accumulated gradients\n",
        "                net.zero_grad()\n",
        "                \n",
        "                # get the output from the model\n",
        "                output, h = net(inputs, h)\n",
        "                \n",
        "                # calculate the loss and perform backprop\n",
        "                loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "                loss.backward()\n",
        "                # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "                nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "                opt.step()\n",
        "                \n",
        "                # loss stats\n",
        "                if counter % print_every == 0:\n",
        "                    # Get validation losstrain_model\n",
        "                    val_h = net.init_hidden(batch_size)\n",
        "                    val_losses = []\n",
        "                    net.eval()\n",
        "                    for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "                        # One-hot encode our data and make them Torch tensors\n",
        "                        x = one_hot_encode(x, n_chars)\n",
        "                        x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "                        \n",
        "                        # Creating new variables for the hidden state, otherwise\n",
        "                        # we'd backprop through the entire training history\n",
        "                        val_h = tuple([each.data for each in val_h])\n",
        "                        \n",
        "                        inputs, targets = x, y\n",
        "                        if(train_on_gpu):\n",
        "                            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "    \n",
        "                        output, val_h = net(inputs, val_h)\n",
        "                        val_loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "                    \n",
        "                        val_losses.append(val_loss.item())\n",
        "                    \n",
        "                    net.train() # reset to train mode after iterationg through validation data\n",
        "                    \n",
        "                    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                          \"Step: {}...\".format(counter),\n",
        "                          \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                          \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y074QG1xda_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f5cfddbf-7273-4f06-b860-57099d8a0915"
      },
      "source": [
        "## define and print the net\n",
        "n_hidden = 512\n",
        "n_layers = 2\n",
        "\n",
        "net = CharRNN(chars, n_hidden, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CharRNN(\n",
            "  (lstm): LSTM(176, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=176, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghwshTXJdbBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "6fffd6e8-c12f-4c1d-8a35-42bab406a246"
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "\n",
        "train(net, encoded, epochs=10, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10... Step: 1000... Loss: 2.0460... Val Loss: 2.0354\n",
            "Epoch: 1/10... Step: 2000... Loss: 1.8264... Val Loss: 1.7554\n",
            "Epoch: 1/10... Step: 3000... Loss: 1.6588... Val Loss: 1.6266\n",
            "Epoch: 1/10... Step: 4000... Loss: 1.5721... Val Loss: 1.5593\n",
            "Epoch: 2/10... Step: 5000... Loss: 1.5643... Val Loss: 1.5159\n",
            "Epoch: 2/10... Step: 6000... Loss: 1.5444... Val Loss: 1.4868\n",
            "Epoch: 2/10... Step: 7000... Loss: 1.5380... Val Loss: 1.4669\n",
            "Epoch: 2/10... Step: 8000... Loss: 1.5074... Val Loss: 1.4502\n",
            "Epoch: 3/10... Step: 9000... Loss: 1.4790... Val Loss: 1.4340\n",
            "Epoch: 3/10... Step: 10000... Loss: 1.4776... Val Loss: 1.4243\n",
            "Epoch: 3/10... Step: 11000... Loss: 1.5075... Val Loss: 1.4166\n",
            "Epoch: 3/10... Step: 12000... Loss: 1.4722... Val Loss: 1.4082\n",
            "Epoch: 4/10... Step: 13000... Loss: 1.4265... Val Loss: 1.4000\n",
            "Epoch: 4/10... Step: 14000... Loss: 1.4354... Val Loss: 1.3938\n",
            "Epoch: 4/10... Step: 15000... Loss: 1.4279... Val Loss: 1.3906\n",
            "Epoch: 4/10... Step: 16000... Loss: 1.4398... Val Loss: 1.3847\n",
            "Epoch: 5/10... Step: 17000... Loss: 1.4311... Val Loss: 1.3758\n",
            "Epoch: 5/10... Step: 18000... Loss: 1.3960... Val Loss: 1.3724\n",
            "Epoch: 5/10... Step: 19000... Loss: 1.4006... Val Loss: 1.3706\n",
            "Epoch: 5/10... Step: 20000... Loss: 1.4476... Val Loss: 1.3660\n",
            "Epoch: 5/10... Step: 21000... Loss: 1.4547... Val Loss: 1.3630\n",
            "Epoch: 6/10... Step: 22000... Loss: 1.4072... Val Loss: 1.3588\n",
            "Epoch: 6/10... Step: 23000... Loss: 1.4428... Val Loss: 1.3582\n",
            "Epoch: 6/10... Step: 24000... Loss: 1.3547... Val Loss: 1.3542\n",
            "Epoch: 6/10... Step: 25000... Loss: 1.3853... Val Loss: 1.3518\n",
            "Epoch: 7/10... Step: 26000... Loss: 1.4240... Val Loss: 1.3489\n",
            "Epoch: 7/10... Step: 27000... Loss: 1.3907... Val Loss: 1.3463\n",
            "Epoch: 7/10... Step: 28000... Loss: 1.3987... Val Loss: 1.3444\n",
            "Epoch: 7/10... Step: 29000... Loss: 1.3868... Val Loss: 1.3440\n",
            "Epoch: 8/10... Step: 30000... Loss: 1.4022... Val Loss: 1.3416\n",
            "Epoch: 8/10... Step: 31000... Loss: 1.3965... Val Loss: 1.3385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hSR5drSdbEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, char, h=None, top_k=None):\n",
        "        ''' Given a character, predict the next character.\n",
        "            Returns the predicted character and the hidden state.\n",
        "        '''\n",
        "        \n",
        "        # tensor inputs\n",
        "        x = np.array([[net.char2int[char]]])\n",
        "        x = one_hot_encode(x, len(net.chars))\n",
        "        inputs = torch.from_numpy(x)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # detach hidden state from history\n",
        "        h = tuple([each.data for each in h])\n",
        "        # get the output of the model\n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # get the character probabilities\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "        \n",
        "        # get top characters\n",
        "        if top_k is None:\n",
        "            top_ch = np.arange(len(net.chars))\n",
        "        else:\n",
        "            p, top_ch = p.topk(top_k)\n",
        "            top_ch = top_ch.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next character with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        char = np.random.choice(top_ch, p=p/p.sum())\n",
        "        \n",
        "        # return the encoded value of the predicted char and the hidden state\n",
        "        return net.int2char[char], h"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1kqujuddbGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(net, size, prime='você', top_k=None):\n",
        "        \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    else:\n",
        "        net.cpu()\n",
        "    \n",
        "    net.eval() # eval mode\n",
        "    \n",
        "    # First off, run through the prime characters\n",
        "    chars = [ch for ch in prime]\n",
        "    h = net.init_hidden(1)\n",
        "    for ch in prime:\n",
        "        char, h = predict(net, ch, h, top_k=top_k)\n",
        "\n",
        "    chars.append(char)\n",
        "    \n",
        "    # Now pass in the previous character and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iatSkZD_dvBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bc9e1c4e-5d65-4d87-bb48-19a7082bc870"
      },
      "source": [
        "poema = sample(net, 200, prime='amor', top_k=2)\n",
        "poema"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'amor, este prazer de amar e de conta de mim, e a minha alma é a minha alegria....  A mentira do coração é a mesma esperança. A mesa está provoco o meu passado em todas as coisas. A casa é uma canção de sen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IYlRQZVnMYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7c9b5641-dbc9-45c0-af1f-e5adb847e8d0"
      },
      "source": [
        "poema = sample(net, 200, prime='amor', top_k=20)\n",
        "poema"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'amor. O caso, mesmo há humanas chorando, chovem e bronzenados de claro cegodepois de emergirtantes do desejo.Abrindo-me à hora, os prestádiospobreráviques eixes, franzes.Mas sei aos murmúrios dos dias,os p'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKOROn8yonpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cc105af9-9fce-4346-bc15-9dde2b356a08"
      },
      "source": [
        "poema = sample(net, 200, prime='amor', top_k=100)\n",
        "poema"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'amor; se um madulo se lireia onde cãos-dia, como ora universal apenas expressa da escravidão e o nosso bambe se passa um tiráculo daquela dor; e se ao pescar-lhe morro, tanta paixão de Primavera. Mas me pe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6mbQByZBjNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}